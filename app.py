import streamlit as st
from streamlit_extras.app_logo import add_logo
from st_pages import Page, Section, show_pages, add_page_title
from selenium import webdriver
from selenium.webdriver.common.by import By
from datetime import date
from bs4 import BeautifulSoup
import pandas as pd
import time
import openai
import altair as alt
import ast 
import os 

openai.api_key = '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'



add_selectbox = st.sidebar.selectbox(
    "ê²Œì„ì„ ì„ íƒí•˜ì„¸ìš”",
    ("ìš°ë§ˆë¬´ìŠ¤ë©”", "ì˜¤ë”˜", "ì•„í‚¤ì—ì´ì§€ì›Œ", "ì—ë²„ì†Œìš¸")
)

# Using "with" notation
with st.sidebar:
    limit = st.radio(
        "ìµœê·¼ ë°ì´í„° ìˆ˜",
        ("10", "50")
    )
    board_type = st.radio(
        "ê²Œì‹œíŒ ì¢…ë¥˜",
        ("ê±´ì˜","ììœ ")
    )
    show = st.button("ê²°ê³¼ ë³´ê¸°")



if show:
    st.header(f'ğŸ¤– GPT ê´€ì ì˜ {add_selectbox} {board_type} ê²Œì‹œíŒ ')    

    col1, col2 = st.columns(2)
    if board_type=="ê±´ì˜":
        bdex= 1
    else:
        bdex=2


    mappings = {
        "ìš°ë§ˆë¬´ìŠ¤ë©”" : ["umamusume-kor", "ZaXF", "Z4oy"],
        "ì˜¤ë”˜" : ["odin", "DEIV", "D034"],
        "ì•„í‚¤ì—ì´ì§€ì›Œ" : ["ArcheAgeWar", "aaTV","ZmF6"],
        "ì—ë²„ì†Œìš¸": ["Eversoul", "aCex", "Zkxr"]
    }
    
    limit_map = {
        "10": "1",
        "20": "2",
        "30": "3",
        "40": "4",
        "50": "5"
    }

    @st.cache_data
    def get_raw_data(cafe_name, req_board_name, limit):
        driver = webdriver.Chrome()
        page = driver.get(f'https://cafe.daum.net/{cafe_name}/{req_board_name}')
        driver.switch_to.frame("down")
        driver.find_element(By.XPATH,'//*[@id="primaryContent"]/div/div[1]/div[2]/div[3]/div[1]/label').click()
        time.sleep(2)

        driver.find_element(By.XPATH,'//*[@id="primaryContent"]/div/div[1]/div[2]/div[3]/div[2]/a').click()
        time.sleep(2)

        driver.find_element(By.XPATH,f'//*[@id="primaryContent"]/div/div[5]/div[2]/div/div[{limit}]/a').click()
        time.sleep(2)


        html = driver.page_source
        soup = BeautifulSoup(html, 'html.parser') 
        profile = soup.select('#cafeProfileImage > img')[0]['src']
        add_logo(profile)

        post_titles = soup.find_all('a', {'class': 'txt_item'})
        article_num = soup.find_all('div',{'class':'wrap_num'})
        views = soup.find_all('span', {'class': 'tbl_txt_look'})
        rec_counts = soup.find_all('span',{'class':'tbl_txt_recommend'})
        dates = soup.find_all('td',{'class': 'td_date'})
        writer = soup.find_all('td',{'class': 'td_writer'})
        recomm =[]
        titles = []
        clicks = []
        article_id = []
        regdate = []
        author = []
        for ele in rec_counts:
            recomm.append(ele.get_text())

        for ele in views:
            clicks.append(ele.get_text())

        for ele in article_num:
            article_id.append(ele.get_text())

        for ele in post_titles:
            titles.append(ele.get_text())

        for e in writer:
            author.append(e.get_text())
        for e in dates:
            if str(e.get_text()).startswith('23.') == False:
                today = date.today().strftime("%y.%m.%d")
                regdate.append(today)
            else:
                regdate.append(e.get_text())
        data = { 'id': article_id, 'titles' : titles, 'recommendations': recomm, 'views': clicks , 'regdate': regdate, 'author':author}
        df = pd.DataFrame(data)
        df['views'] =  pd.to_numeric(df['views'])
        df['link'] = f'https://cafe.daum.net/{cafe_name}/{req_board_name}/' + df['id']
        return df


    def get_answers_from_gpt(command,temp):
        completion = openai.ChatCompletion.create (

        model = 'gpt-3.5-turbo-0613',
        messages = [{"role": "user", "content": command}],
        temperature=temp
        )
        return completion['choices'][0]['message']['content']


    @st.cache_data  
    def add_specific_contents(df):
        driver = webdriver.Chrome()
        contents = []
        for index, row in df.iterrows():
            url = df.iloc[index]['link']
            page = driver.get(url)
            driver.switch_to.frame("down")
            html = driver.page_source
            soup = BeautifulSoup(html, 'html.parser') 
            if len(soup.select('#user_contents')) == 0 :
                contents.append('')
            else :
                texts = soup.select('#user_contents')[0].get_text()
                contents.append(texts.replace(u'\xa0', u' ').lstrip())
        df['contents']=contents
        return contents

    @st.cache_data
    def add_summary(df):
        summary = []
        for ele in df['contents']:
            command = f"""
                ì•„ë˜ì˜ ê±´ì˜ì‚¬í•­ì„ í•œë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜. 
                {ele}
                """
            completion = openai.ChatCompletion.create (

                model = 'gpt-3.5-turbo-0613',
                messages = [{"role": "user", "content": command}]
                
                )
            summary.append(completion['choices'][0]['message']['content'])
        df['summary'] = summary
        return df



    if add_selectbox == "ì˜¤ë”˜" and board_type == "ììœ ":
        df = get_raw_data(mappings[add_selectbox][0],mappings[add_selectbox][2], limit_map[limit])
        add_specific_contents(df)
        add_summary(df)
        sent_cmd = f"""

                ì•„ë˜ ì „ë‹¬í•˜ëŠ” listëŠ” ê²Œì„ ê±´ì˜ ì œëª©ì´ì•¼.
                ê°ê°ì˜ sentiment analysisë¥¼ í•´ì„œ -1ê³¼ 1 ì‚¬ì´ì˜ ê°’ì„ ì„¤ëª… ì—†ì´ lengthê°€ listì™€ ë™ì¼í•œ python listë¡œ ì „ë‹¬í•´ì¤˜. 

                {df['titles']}
                """
        sentiments = get_answers_from_gpt(sent_cmd,0.3)
        sentiments=ast.literal_eval(sentiments)
        print(sentiments)
        df['sentiments'] = sentiments
    else: 
        df = pd.read_csv(f'{mappings[add_selectbox][0]}-{mappings[add_selectbox][bdex]}.csv')


    # TOO SLOW 
    # if board_type == 'ììœ ':
    #     df = get_raw_data(mappings[add_selectbox][0],mappings[add_selectbox][2], limit_map[limit])
    #     add_specific_contents(df)
    #     add_summary(df)
    # else:
    #     df = get_raw_data(mappings[add_selectbox][0],mappings[add_selectbox][1], limit_map[limit])
    #     add_specific_contents(df)
    #     add_summary(df)
    # Streamlit UI 



    # sent_cmd = f"""

    # ì•„ë˜ ì „ë‹¬í•˜ëŠ” listëŠ” ê²Œì„ ê±´ì˜ ì œëª©ì´ì•¼.
    # ê°ê°ì˜ sentiment analysisë¥¼ í•´ì„œ -1ê³¼ 1 ì‚¬ì´ì˜ ê°’ì„ ì„¤ëª… ì—†ì´ lengthê°€ listì™€ ë™ì¼í•œ python listë¡œ ì „ë‹¬í•´ì¤˜. 

    # {df['titles']}
    # """
    # sentiments = get_answers_from_gpt(sent_cmd,0.3)
    # sentiments=ast.literal_eval(sentiments)
    # print(sentiments)
    # df['sentiments'] = sentiments

    date_count = df.groupby(df['regdate']).size().reset_index(name='Count')
    
    st.markdown("### ê±´ì˜í•¨ 5ê°€ì§€ ì‹œì‚¬ì ")
    issues = get_answers_from_gpt(f"""
            ì•„ë˜ëŠ” ê±´ì˜í•¨ ë‚´ìš©ë“¤ì¸ë° ì£¼ìš” ê±´ì˜ ì‚¬í•­ 5ê°€ì§€ë¡œ ìš”ì•½í•´ì„œ ì•Œë ¤ì¤˜.  
            {df['titles']}
            """, 0.8)
    st.write(issues) 


    hot_issues = df.sort_values(by=['views','recommendations'],ascending=False)[:10]
    st.markdown("### ì¡°íšŒìˆ˜, ì¶”ì²œìˆ˜ ë†’ì€!")
    st.write(hot_issues[["link","titles","summary"]]) 


    with col1:
        st.markdown("### ê±´ì˜í•¨ í˜„í™©")
        st.line_chart(date_count, x='regdate',y='Count')

        

  

    with col2:
        st.markdown("### ê±´ì˜í•¨ ë¹ˆë„ ë†’ì€ í‚¤ì›Œë“œ")
        keywords = get_answers_from_gpt(f"""
        ì•„ë˜ëŠ” ê²Œì„ ê±´ì˜í•¨ ë‚´ìš©ë“¤ì¸ë° ë¹ˆë„ê°€ ë†’ì€ ë‹¨ì–´ ë‹¤ì„¯ê°€ì§€ì™€ ë¹ˆë„ í¼ì„¼íŠ¸ë¥¼ ì•Œë ¤ì¤˜.
        {df['titles']}
        """, 0.8)
        st.write(keywords) 


    st.markdown("### ìµœì‹  ë°ì´í„°")
    st.write(df)

    st.markdown("### ê±´ì˜í•¨ sentiment analysis")
    sentiment_count = df.groupby(df['sentiments']).size().reset_index(name='Count')
    s_data = alt.Chart(df[["sentiments","regdate",'titles']]).mark_circle().encode(
        x='regdate', y='sentiments', size='sentiments', color='sentiments')
    st.altair_chart(s_data, use_container_width=True)

  
